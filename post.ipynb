{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past year or so, I've been using [JAX](https://jax.readthedocs.io) extensively for my research, and I've also been encouraging other astronomers to give it a try.\n",
    "In particular, I've been using JAX as the computation engine for probabilistic inference tasks.\n",
    "\n",
    "## An introduction to JAX\n",
    "\n",
    "There's more to it, but one way that I like to think about JAX is as NumPy with just-in-time compilation and [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
    "The just-in-time compilation features of JAX can be used to speed up you NumPy computations by removing some Python overhead and by executing it on your GPU.\n",
    "These optimizations can be useful for a wide range of applications, but JAX especially shines when using automatic differentiation for improving your inference algorithms.\n",
    "\n",
    "While it's not true that naively using JAX will automatically speed up you code, in many cases it will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll choose the parameters of our synthetic data.\n",
    "# The outlier probability will be 80%:\n",
    "true_frac = 0.8\n",
    "\n",
    "# The linear model has unit slope and zero intercept:\n",
    "true_params = [1.0, 0.0]\n",
    "\n",
    "# The outliers are drawn from a Gaussian with zero mean and unit variance:\n",
    "true_outliers = [0.0, 1.0]\n",
    "\n",
    "# For reproducibility, let's set the random number seed and generate the data:\n",
    "np.random.seed(12)\n",
    "x = np.sort(np.random.uniform(-2, 2, 15))\n",
    "yerr = 0.2 * np.ones_like(x)\n",
    "y = true_params[0] * x + true_params[1] + yerr * np.random.randn(len(x))\n",
    "\n",
    "# Those points are all drawn from the correct model so let's replace some of\n",
    "# them with outliers.\n",
    "m_bkg = np.random.rand(len(x)) > true_frac\n",
    "y[m_bkg] = true_outliers[0]\n",
    "y[m_bkg] += np.sqrt(true_outliers[1] + yerr[m_bkg] ** 2) * np.random.randn(sum(m_bkg))\n",
    "\n",
    "# Then save the *true* line.\n",
    "x0 = np.linspace(-2.1, 2.1, 200)\n",
    "y0 = np.dot(np.vander(x0, 2), true_params)\n",
    "\n",
    "# Plot the data and the truth.\n",
    "plt.errorbar(x, y, yerr=yerr, fmt=\",k\", ms=0, capsize=0, lw=1, zorder=999)\n",
    "plt.scatter(x[m_bkg], y[m_bkg], marker=\"s\", s=22, c=\"w\", edgecolor=\"k\", zorder=1000)\n",
    "plt.scatter(x[~m_bkg], y[~m_bkg], marker=\"o\", s=22, c=\"k\", zorder=1000)\n",
    "plt.plot(x0, y0, color=\"k\", lw=1.5)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.ylim(-2.5, 2.5)\n",
    "plt.xlim(-2.1, 2.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpyro\n",
    "\n",
    "numpyro.set_host_device_count(2)\n",
    "from numpyro import distributions as dist, infer\n",
    "\n",
    "\n",
    "def linear_model(x, yerr, y=None):\n",
    "    theta = numpyro.sample(\"theta\", dist.Uniform(-0.5 * jnp.pi, 0.5 * jnp.pi))\n",
    "    b_perp = numpyro.sample(\"b_perp\", dist.Normal(0, 1))\n",
    "\n",
    "    # Transformed parameters (and other things!) can be tracked during sampling using\n",
    "    # \"deterministics\" as follows:\n",
    "    m = numpyro.deterministic(\"m\", jnp.tan(theta))\n",
    "    b = numpyro.deterministic(\"b\", b_perp / jnp.cos(theta))\n",
    "\n",
    "    numpyro.sample(\"obs\", dist.Normal(m * x + b, yerr), obs=y)\n",
    "\n",
    "\n",
    "sampler = infer.MCMC(\n",
    "    infer.NUTS(linear_model),\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    ")\n",
    "%time sampler.run(jax.random.PRNGKey(0), x, yerr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import arviz as az\n",
    "\n",
    "inf_data = az.from_numpyro(sampler)\n",
    "corner.corner(inf_data, var_names=[\"m\", \"b\"], truths=true_params)\n",
    "az.summary(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro_ext.distributions import MixtureGeneral\n",
    "\n",
    "\n",
    "def linear_mixture_model(x, yerr, y=None):\n",
    "    # Foreground model\n",
    "    theta = numpyro.sample(\"theta\", dist.Uniform(-0.5 * jnp.pi, 0.5 * jnp.pi))\n",
    "    b_perp = numpyro.sample(\"b_perp\", dist.Normal(0.0, 1.0))\n",
    "    m = numpyro.deterministic(\"m\", jnp.tan(theta))\n",
    "    b = numpyro.deterministic(\"b\", b_perp / jnp.cos(theta))\n",
    "    fg_dist = dist.Normal(m * x + b, yerr)\n",
    "\n",
    "    # Background model\n",
    "    bg_mean = numpyro.sample(\"bg_mean\", dist.Normal(0.0, 1.0))\n",
    "    bg_sigma = numpyro.sample(\"bg_sigma\", dist.HalfNormal(3.0))\n",
    "    bg_dist = dist.Normal(bg_mean, jnp.sqrt(bg_sigma**2 + yerr**2))\n",
    "\n",
    "    # Mixture\n",
    "    Q = numpyro.sample(\"Q\", dist.Uniform(0.0, 1.0))\n",
    "    mix = dist.Categorical(probs=jnp.array([Q, 1.0 - Q]))\n",
    "    numpyro.sample(\"obs\", MixtureGeneral(mix, [fg_dist, bg_dist]), obs=y)\n",
    "\n",
    "\n",
    "sampler = infer.MCMC(\n",
    "    infer.NUTS(linear_mixture_model),\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    ")\n",
    "%time sampler.run(jax.random.PRNGKey(10), x, yerr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = az.from_numpyro(sampler)\n",
    "corner.corner(\n",
    "    inf_data,\n",
    "    var_names=[\"m\", \"b\", \"Q\"],\n",
    "    truths={\n",
    "        \"m\": true_params[0],\n",
    "        \"b\": true_params[1],\n",
    "        \"Q\": true_frac,\n",
    "    },\n",
    ")\n",
    "az.summary(inf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "with fits.open(\"data/m67.fits.gz\") as f:\n",
    "    data = f[1].data\n",
    "\n",
    "mask = np.isfinite(data[\"parallax\"])\n",
    "mask &= np.isfinite(data[\"parallax_error\"])\n",
    "mask &= data[\"parallax\"] > 0.5\n",
    "mask &= data[\"parallax\"] < 2.0\n",
    "data = data[mask]\n",
    "\n",
    "plt.hist(data[\"parallax\"], 120, histtype=\"step\")\n",
    "plt.xlabel(\"parallax [mas]\")\n",
    "plt.ylabel(\"count\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A brief aside:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "L = 370.0\n",
    "x = np.linspace(0, 5000, 500)\n",
    "r = 0.5 * L * stats.chi2(df=6).rvs(500_000)\n",
    "plt.hist(r, 100, range=(0, 5000), density=True, histtype=\"step\", label=\"samples\")\n",
    "plt.plot(x, 0.5 * x**2 * np.exp(-x / L) / L**3, \"--\", label=\"pdf\")\n",
    "plt.xlabel(\"distance [pc]\")\n",
    "plt.yticks([])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaia_single_model(plx_err, plx=None, plx_zp=0.0, L=370.0):\n",
    "    normed = numpyro.sample(\"normed\", dist.Chi2(6))\n",
    "    distance = numpyro.deterministic(\"distance\", 0.5 * L * normed)\n",
    "    numpyro.sample(\"plx\", dist.Normal(1000.0 / distance + plx_zp, plx_err), obs=plx)\n",
    "\n",
    "\n",
    "plx = data[750][\"parallax\"]\n",
    "plx_err = data[750][\"parallax_error\"]\n",
    "\n",
    "sampler = infer.MCMC(\n",
    "    infer.NUTS(gaia_single_model),\n",
    "    num_warmup=1000,\n",
    "    num_samples=5000,\n",
    "    num_chains=2,\n",
    ")\n",
    "%time sampler.run(jax.random.PRNGKey(0), plx_err, plx=plx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_single = sampler.get_samples()\n",
    "plt.hist(samples_single[\"distance\"], 50, density=True, histtype=\"step\")\n",
    "plt.xlabel(\"distance [pc]\")\n",
    "plt.ylabel(\"posterior density\")\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaia_cluster_model(plx_err, plx=None, plx_zp=0.0):\n",
    "    N = len(plx_err)\n",
    "    log_L = numpyro.sample(\"log_L\", dist.Normal(np.log(370.0), 2.0))\n",
    "    log_mu = numpyro.sample(\"log_mu\", dist.Normal(np.log(920.0), 2.0))\n",
    "    log_sigma = numpyro.sample(\"log_sigma\", dist.Normal(0.0, 2.0))\n",
    "    prob_fg = numpyro.sample(\"prob_fg\", dist.Uniform())\n",
    "\n",
    "    with numpyro.plate(\"stars\", N):\n",
    "        dist_bg = dist.TransformedDistribution(\n",
    "            dist.Chi2(6),\n",
    "            dist.transforms.AffineTransform(\n",
    "                0.0, 0.5 * jnp.exp(log_L), domain=dist.constraints.positive\n",
    "            ),\n",
    "        )\n",
    "        dist_fg = dist.TransformedDistribution(\n",
    "            dist.Normal(),\n",
    "            [\n",
    "                dist.transforms.AffineTransform(log_mu, jnp.exp(log_sigma)),\n",
    "                dist.transforms.ExpTransform(),\n",
    "            ],\n",
    "        )\n",
    "        mix = MixtureGeneral(\n",
    "            dist.Categorical(probs=jnp.stack((prob_fg, 1 - prob_fg), axis=-1)),\n",
    "            [dist_fg, dist_bg],\n",
    "        )\n",
    "\n",
    "        distance = numpyro.sample(\"distance\", mix)\n",
    "\n",
    "        log_probs = mix.component_log_probs(distance)\n",
    "        numpyro.deterministic(\n",
    "            \"log_p_member\", log_probs - jax.nn.logsumexp(log_probs, axis=-1)[..., None]\n",
    "        )\n",
    "\n",
    "        plx_model = numpyro.deterministic(\"plx\", 1000.0 / distance + plx_zp)\n",
    "        numpyro.sample(\"obs\", dist.Normal(plx_model, plx_err), obs=plx)\n",
    "\n",
    "\n",
    "plx = np.ascontiguousarray(data[\"parallax\"], dtype=np.float32)\n",
    "plx_err = np.ascontiguousarray(data[\"parallax_error\"], dtype=np.float32)\n",
    "\n",
    "sampler = infer.MCMC(\n",
    "    infer.NUTS(gaia_cluster_model),\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    ")\n",
    "%time sampler.run(jax.random.PRNGKey(0), plx_err, plx=plx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.get_samples()\n",
    "plt.hist(samples_single[\"distance\"], 50, density=True, histtype=\"step\")\n",
    "plt.hist(samples[\"distance\"][:, 750], 50, density=True, histtype=\"step\")\n",
    "plt.xlabel(\"distance [pc]\")\n",
    "plt.ylabel(\"posterior density\")\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = az.from_numpyro(sampler)\n",
    "corner.corner(inf_data, var_names=[\"log_L\", \"log_mu\", \"log_sigma\", \"prob_fg\"])\n",
    "az.summary(inf_data, var_names=[\"log_L\", \"log_mu\", \"log_sigma\", \"prob_fg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4c445ddd5eb40af76c64959af70f0a315c6821d655f4e1ee71e79b5a8cc47f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
